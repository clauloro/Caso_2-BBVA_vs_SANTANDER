{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fec7b02",
   "metadata": {},
   "source": [
    "### 3.6. Optimización de hiperparámetros\n",
    "\n",
    "Se realizó una búsqueda exhaustiva (**Grid Search**) sobre los modelos **LSTM** y **GRU**, evaluando las combinaciones:\n",
    "\n",
    "- **Tamaño de ventana** (`window_size`): 10, 20, 30  \n",
    "- **Unidades recurrentes** (`units`): 32, 64, 128  \n",
    "- **Tamaño de lote** (`batch_size`): 32, 64  \n",
    "- **Tasa de aprendizaje** (`learning_rate`): 0.001, 0.0005  \n",
    "\n",
    "**Protocolo de evaluación.**  \n",
    "Los datos se dividieron respetando el orden temporal: 80 % para entrenamiento y 20 % para prueba.  \n",
    "Dentro del bloque de entrenamiento, el **10 % final** se empleó como **validación**.  \n",
    "La métrica de selección fue el **MSE (Error Cuadrático Medio)** en validación.\n",
    "\n",
    "**Procedimiento.**  \n",
    "Para cada combinación de hiperparámetros y cada arquitectura (LSTM/GRU), el modelo se entrenó con `EarlyStopping` y se registró el MSE en validación.  \n",
    "La mejor configuración se **reentrenó en train+val** y se evaluó en el conjunto de **prueba**, reportando **MAE, RMSE y MSE**.\n",
    "\n",
    "Este esquema garantiza una comparación justa entre configuraciones, evita la fuga temporal y ofrece una línea base sólida para los modelos recurrentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6cf2750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivos detectados:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "⚠️ Solo CPU detectada, será mucho más lento.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Dispositivos detectados:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"✅ TensorFlow está usando GPU correctamente.\")\n",
    "else:\n",
    "    print(\"⚠️ Solo CPU detectada, será mucho más lento.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3c25dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BBVA =====\n",
      "window=10 | X_train=(4752, 10, 16), X_val=(520, 10, 16), X_test=(1313, 10, 16)\n",
      "WARNING:tensorflow:From c:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 126\u001b[39m\n\u001b[32m    121\u001b[39m model = builder(n_features=n_features, units=units, lr=lr)\n\u001b[32m    122\u001b[39m cb = [\n\u001b[32m    123\u001b[39m     keras.callbacks.EarlyStopping(monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, patience=PATIENCE,\n\u001b[32m    124\u001b[39m                                   restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m    125\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m hist = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Métrica de validación (criterio de selección)\u001b[39;00m\n\u001b[32m    136\u001b[39m y_val_hat = model.predict(X_val, verbose=\u001b[32m0\u001b[39m).ravel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lopec\\OneDrive\\Documentos\\GitHub\\Caso_2-BBVA_vs_SANTANDER\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 0) Imports y paths\n",
    "# ============================================\n",
    "import os, math, itertools, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "DATA_DIR   = Path(\"../data/processed/ready_for_modeling\")\n",
    "OUT_DIR    = Path(\"../results/hparam_search\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TICKERS = [\"BBVA\", \"SAN\"]\n",
    "TARGET_COL = \"Close\"\n",
    "\n",
    "# Grids (según documento)\n",
    "WINDOW_GRID = [10, 20, 30]\n",
    "UNITS_GRID  = [32, 64, 128]\n",
    "BATCH_GRID  = [32, 64]\n",
    "LR_GRID     = [1e-3, 5e-4]\n",
    "\n",
    "EPOCHS = 120\n",
    "VAL_RATIO_WITHIN_TRAIN = 0.10   # 10% de train para validación\n",
    "TEST_RATIO = 0.20               # 80/20 temporal\n",
    "PATIENCE = 10\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ============================================\n",
    "# 1) Utilidades de secuenciado y splits\n",
    "# ============================================\n",
    "def make_sequences(df, window, horizon=1, target_col=\"Close\"):\n",
    "    Xs, ys = [], []\n",
    "    vals = df.values.astype(np.float32)\n",
    "    y_idx = df.columns.get_loc(target_col)\n",
    "    last_start = len(df) - window - horizon + 1\n",
    "    for s in range(last_start):\n",
    "        e = s + window\n",
    "        Xs.append(vals[s:e, :])\n",
    "        ys.append(vals[e + horizon - 1, y_idx])\n",
    "    return np.stack(Xs), np.array(ys, dtype=np.float32)\n",
    "\n",
    "def temporal_split(df, test_ratio=0.2):\n",
    "    cut = int(len(df) * (1 - test_ratio))\n",
    "    return df.iloc[:cut].copy(), df.iloc[cut:].copy()\n",
    "\n",
    "def split_train_val_by_tail(df_train_block, val_ratio=0.1):\n",
    "    cut = int(len(df_train_block) * (1 - val_ratio))\n",
    "    return df_train_block.iloc[:cut].copy(), df_train_block.iloc[cut:].copy()\n",
    "\n",
    "# ============================================\n",
    "# 2) Model builders\n",
    "# ============================================\n",
    "def build_lstm(n_features, units, lr):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(None, n_features)),\n",
    "        layers.LSTM(units),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_gru(n_features, units, lr):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(None, n_features)),\n",
    "        layers.GRU(units),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# ============================================\n",
    "# 3) Grid Search por ticker y modelo\n",
    "# ============================================\n",
    "def evaluate_on_val(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return mse, rmse, mae\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"\\n===== {ticker} =====\")\n",
    "    df = pd.read_csv(DATA_DIR / f\"{ticker}_final_ready.csv\", parse_dates=[\"Date\"], index_col=\"Date\").sort_index()\n",
    "    n_features = df.shape[1]\n",
    "\n",
    "    # Split temporal 80/20\n",
    "    df_tr_block, df_te_block = temporal_split(df, test_ratio=TEST_RATIO)\n",
    "\n",
    "    # Para cada window generamos secuencias (sin fuga)\n",
    "    for window in WINDOW_GRID:\n",
    "        # train/val dentro del bloque de train\n",
    "        df_tr_core, df_val_core = split_train_val_by_tail(df_tr_block, val_ratio=VAL_RATIO_WITHIN_TRAIN)\n",
    "\n",
    "        X_tr, y_tr   = make_sequences(df_tr_core, window=window, target_col=TARGET_COL)\n",
    "        X_val, y_val = make_sequences(df_val_core, window=window, target_col=TARGET_COL)\n",
    "        X_te,  y_te  = make_sequences(df_te_block,  window=window, target_col=TARGET_COL)\n",
    "\n",
    "        print(f\"window={window} | X_train={X_tr.shape}, X_val={X_val.shape}, X_test={X_te.shape}\")\n",
    "\n",
    "        # Saltar si no hay suficientes puntos para val/test\n",
    "        if X_tr.size == 0 or X_val.size == 0 or X_te.size == 0:\n",
    "            print(\"Insuficientes muestras, se omite esta ventana.\")\n",
    "            continue\n",
    "\n",
    "        # Grid exhaustivo\n",
    "        for units, batch, lr in itertools.product(UNITS_GRID, BATCH_GRID, LR_GRID):\n",
    "            config = dict(window=window, units=units, batch=batch, lr=lr)\n",
    "\n",
    "            for arch_name, builder in [(\"LSTM\", build_lstm), (\"GRU\", build_gru)]:\n",
    "                tf.keras.backend.clear_session()\n",
    "\n",
    "                model = builder(n_features=n_features, units=units, lr=lr)\n",
    "                cb = [\n",
    "                    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE,\n",
    "                                                  restore_best_weights=True, verbose=0)\n",
    "                ]\n",
    "                hist = model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=batch,\n",
    "                    verbose=0,\n",
    "                    callbacks=cb,\n",
    "                )\n",
    "\n",
    "                # Métrica de validación (criterio de selección)\n",
    "                y_val_hat = model.predict(X_val, verbose=0).ravel()\n",
    "                mse_val, rmse_val, mae_val = evaluate_on_val(y_val, y_val_hat)\n",
    "\n",
    "                all_results.append({\n",
    "                    \"Ticker\": ticker, \"Model\": arch_name,\n",
    "                    **config,\n",
    "                    \"val_MSE\": mse_val, \"val_RMSE\": rmse_val, \"val_MAE\": mae_val,\n",
    "                    \"best_epoch\": np.argmin(hist.history[\"val_loss\"]) + 1\n",
    "                })\n",
    "\n",
    "    # Guardar resultados parciales por ticker\n",
    "    df_res_t = pd.DataFrame([r for r in all_results if r[\"Ticker\"] == ticker])\n",
    "    df_res_t.to_csv(OUT_DIR / f\"{ticker}_grid_results.csv\", index=False)\n",
    "    print(f\"→ Guardado grid de {ticker}: {OUT_DIR / (ticker + '_grid_results.csv')}\")\n",
    "\n",
    "# ============================================\n",
    "# 4) Selección de mejor config, retrain en train+val y evaluación en test\n",
    "# ============================================\n",
    "summary_rows = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    df = pd.read_csv(DATA_DIR / f\"{ticker}_final_ready.csv\", parse_dates=[\"Date\"], index_col=\"Date\").sort_index()\n",
    "    n_features = df.shape[1]\n",
    "\n",
    "    # Repetimos splits y secuencias para el BEST window\n",
    "    grid_file = OUT_DIR / f\"{ticker}_grid_results.csv\"\n",
    "    best = pd.read_csv(grid_file).sort_values([\"val_MSE\"]).iloc[0].to_dict()\n",
    "\n",
    "    window = int(best[\"window\"]); units = int(best[\"units\"])\n",
    "    batch  = int(best[\"batch\"]);  lr    = float(best[\"lr\"])\n",
    "    model_name = best[\"Model\"]\n",
    "\n",
    "    # Bloques\n",
    "    df_tr_block, df_te_block = temporal_split(df, test_ratio=TEST_RATIO)\n",
    "    # Train+Val juntos para reentrenar\n",
    "    X_trval, y_trval = make_sequences(df_tr_block, window=window, target_col=TARGET_COL)\n",
    "    X_test,  y_test  = make_sequences(df_te_block,  window=window, target_col=TARGET_COL)\n",
    "\n",
    "    builder = build_lstm if model_name == \"LSTM\" else build_gru\n",
    "    model = builder(n_features=n_features, units=units, lr=lr)\n",
    "    cb = [keras.callbacks.EarlyStopping(monitor=\"loss\", patience=PATIENCE, restore_best_weights=True, verbose=0)]\n",
    "\n",
    "    hist = model.fit(X_trval, y_trval, epochs=EPOCHS, batch_size=batch, verbose=0, callbacks=cb)\n",
    "\n",
    "    # Evaluación en test\n",
    "    y_hat_test = model.predict(X_test, verbose=0).ravel()\n",
    "    mse_te = mean_squared_error(y_test, y_hat_test)\n",
    "    rmse_te = math.sqrt(mse_te)\n",
    "    mae_te = mean_absolute_error(y_test, y_hat_test)\n",
    "\n",
    "    # Guardar predicciones test\n",
    "    preds = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_hat_test})\n",
    "    preds.to_csv(OUT_DIR / f\"{ticker}_{model_name}_best_preds_test.csv\", index=False)\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Ticker\": ticker,\n",
    "        \"BestModel\": model_name, \"window\": window, \"units\": units, \"batch\": batch, \"lr\": lr,\n",
    "        \"Test_MSE\": mse_te, \"Test_RMSE\": rmse_te, \"Test_MAE\": mae_te\n",
    "    })\n",
    "\n",
    "# Resumen final\n",
    "df_summary = pd.DataFrame(summary_rows)\n",
    "df_summary.to_csv(OUT_DIR / \"best_summary.csv\", index=False)\n",
    "print(\"\\n✅ Búsqueda completada. Resumen de mejores configuraciones:\")\n",
    "print(df_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Caso2 (env)",
   "language": "python",
   "name": "caso2-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
